{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import requests\n",
    "import tqdm\n",
    "import json\n",
    "import os\n",
    "from elsapy.elsclient import ElsClient\n",
    "from elsapy.elsprofile import ElsAuthor, ElsAffil\n",
    "from elsapy.elsdoc import FullDoc, AbsDoc\n",
    "from elsapy.elssearch import ElsSearch\n",
    "import pycountry\n",
    "import re\n",
    "from urllib.parse import urlparse, parse_qs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the Elsevier API key\n",
    "def getElsevierAPIKey():\n",
    "    with open(\"apiKey.json\") as f:\n",
    "        data = json.load(f)\n",
    "        return data[\"apiKey\"]\n",
    "\n",
    "# Function to get the author's affiliation\n",
    "def load_data_csv(file_path):\n",
    "    # Create a new Dataframe\n",
    "    data = []\n",
    "    \n",
    "    with open(file_path, newline=\"\") as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        for row in reader:\n",
    "            # Parse JSON strings\n",
    "            json_data_1 = json.loads(row[0])\n",
    "            json_data_2 = json.loads(row[1])\n",
    "            json_data_3 = json.loads(row[2])\n",
    "            \n",
    "            # Append the data to the list\n",
    "            data.append([json_data_1, json_data_2, json_data_3])\n",
    "    \n",
    "    # Filter the data in which json_data_3 == 1\n",
    "    data = [d for d in data if d[2] == 1]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Missed Ones:  1\n",
      "Total Inside Ones:  0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 190 entries, 0 to 189\n",
      "Data columns (total 16 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   SubmissionID              190 non-null    object \n",
      " 1   SubmissionYear            190 non-null    int64  \n",
      " 2   SubmissionTitle           190 non-null    object \n",
      " 3   SubmissionAbstract        0 non-null      float64\n",
      " 4   firstName                 190 non-null    object \n",
      " 5   middleName                48 non-null     object \n",
      " 6   lastName                  190 non-null    object \n",
      " 7   isFirstAuthor             190 non-null    int64  \n",
      " 8   city                      0 non-null      float64\n",
      " 9   country                   190 non-null    object \n",
      " 10  countryCode               190 non-null    object \n",
      " 11  institution               190 non-null    object \n",
      " 12  doi                       190 non-null    object \n",
      " 13  authorID                  190 non-null    object \n",
      " 14  authorPublicationHistory  190 non-null    object \n",
      " 15  match                     190 non-null    int64  \n",
      "dtypes: float64(2), int64(3), object(11)\n",
      "memory usage: 23.9+ KB\n",
      "None\n",
      "         SubmissionID  SubmissionYear  \\\n",
      "0  /10.1063/1.5004606            2018   \n",
      "1  /10.1063/1.5004606            2018   \n",
      "2  /10.1063/1.5004606            2018   \n",
      "3  /10.1063/1.5004606            2018   \n",
      "4  /10.1063/1.5004606            2018   \n",
      "\n",
      "                                     SubmissionTitle  SubmissionAbstract  \\\n",
      "0  Characterizing highly dynamic conformational s...                 NaN   \n",
      "1  Characterizing highly dynamic conformational s...                 NaN   \n",
      "2  Characterizing highly dynamic conformational s...                 NaN   \n",
      "3  Characterizing highly dynamic conformational s...                 NaN   \n",
      "4  Characterizing highly dynamic conformational s...                 NaN   \n",
      "\n",
      "  firstName middleName    lastName  isFirstAuthor  city        country  \\\n",
      "0     Eitan        NaN      Lerner              1   NaN  United States   \n",
      "1  Antonino        NaN  Ingargiola              0   NaN  United States   \n",
      "2    Shimon        NaN       Weiss              0   NaN  United States   \n",
      "3     Eitan        NaN      Lerner              1   NaN  United States   \n",
      "4  Antonino        NaN  Ingargiola              0   NaN  United States   \n",
      "\n",
      "  countryCode                            institution              doi  \\\n",
      "0          US  University of California, Los Angeles  /10.1101/188524   \n",
      "1          US  University of California, Los Angeles  /10.1101/188524   \n",
      "2          US  University of California, Los Angeles  /10.1101/188524   \n",
      "3          US  University of California, Los Angeles  /10.1101/188524   \n",
      "4          US  University of California, Los Angeles  /10.1101/188524   \n",
      "\n",
      "      authorID                           authorPublicationHistory  match  \n",
      "0  35205792300  [{'title': 'Rapid and specific detection of na...      1  \n",
      "1  23973120100  [{'title': 'Erratum: Monte Carlo Diffusion-Enh...      1  \n",
      "2   7403678118  [{'title': 'Dynamic stability of Sgt2 enables ...      1  \n",
      "3  35205792300  [{'title': 'Rapid and specific detection of na...      1  \n",
      "4  23973120100  [{'title': 'Erratum: Monte Carlo Diffusion-Enh...      1  \n"
     ]
    }
   ],
   "source": [
    "def fetch_openalex_data(doi):\n",
    "    url = f\"https://api.openalex.org/works/https://doi.org/{doi}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        #print(response.json())\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(response)\n",
    "        print(f\"Error fetching data for DOI: {doi}\")\n",
    "        return None\n",
    "\n",
    "def get_country_name(country_code):\n",
    "    try:\n",
    "        country = pycountry.countries.get(alpha_2=country_code)\n",
    "        return country.name\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "if os.path.exists(\"./data/openalex_data.csv\"):\n",
    "    openalex_df = pd.read_csv(\"./data/openalex_data.csv\")\n",
    "else:\n",
    "    df = pd.read_csv(\"./data/mini_dataset.csv\")\n",
    "    openalex_data = []\n",
    "    missedOut = 0\n",
    "    inside = 0\n",
    "    out = 0\n",
    "    for index, row in tqdm.tqdm(df.iterrows(), total=df.shape[0]):\n",
    "        doi = row[\"PreprintID\"]\n",
    "        pubdoi = row[\"PublicationID\"]\n",
    "        match = row[\"Match\"]\n",
    "        temp = doi\n",
    "        doi = pubdoi\n",
    "        pubdoi = temp\n",
    "        data = fetch_openalex_data(doi)\n",
    "        if data:\n",
    "            language = data.get(\"language\", None)\n",
    "            if language == \"en\":\n",
    "                break_outer_loop = False\n",
    "                inside_data = []\n",
    "                submissionID = data.get(\"doi\", None)\n",
    "                \n",
    "                submissionID = submissionID[15:]\n",
    "                submissionYear = data.get(\"publication_year\")\n",
    "                submissionTitle = data.get(\"title\", None)\n",
    "                authors = data.get(\"authorships\", [])\n",
    "                if (len(authors) != 0):\n",
    "                    \n",
    "                    \n",
    "                    for author in authors:\n",
    "                        notFound = True\n",
    "                        fullName = author.get(\"author\", {}).get(\"display_name\", None)\n",
    "                        if (len(fullName.split()) == 2):\n",
    "                            firstName, lastName = fullName.split()\n",
    "                            middleName = None\n",
    "                        elif (len(fullName.split()) == 3):\n",
    "                            firstName, middleName, lastName = fullName.split()\n",
    "                        else:\n",
    "                            firstName = fullName\n",
    "                            middleName = None\n",
    "                            lastName = None\n",
    "                        isFirstAuthor = author.get(\"author_position\", None)\n",
    "                        if isFirstAuthor == \"first\":\n",
    "                            isFirstAuthor = 1\n",
    "                        else:\n",
    "                            isFirstAuthor = 0\n",
    "                        if len(author.get(\"institutions\", [])) != 0:\n",
    "                            countryCode = author.get(\"institutions\", [])[0].get(\"country_code\", None)\n",
    "                            country = get_country_name(countryCode) if countryCode else None\n",
    "                            institution = author.get(\"institutions\", [])[0].get(\"display_name\", None)\n",
    "                        else:\n",
    "                            #print(\"No institutions\")\n",
    "                            break_outer_loop = True\n",
    "                            break\n",
    "                        doi = pubdoi\n",
    "                        if None in [submissionID, submissionYear, submissionTitle, firstName, lastName, isFirstAuthor, country, countryCode, institution, doi]:\n",
    "                            #print(f\"Breaking at index {index} due to missing values\")\n",
    "                            #print(f\"submissionID: {submissionID}, submissionYear: {submissionYear}, submissionTitle: {submissionTitle}, firstName: {firstName},lastName: {lastName}, isFirstAuthor: {isFirstAuthor}, country: {country}, countryCode: {countryCode}, institution: {institution}, doi:{doi}\")\n",
    "                            break_outer_loop = True\n",
    "                            break\n",
    "                        \n",
    "                        authorId = author.get(\"author\", {}).get(\"id\", None)\n",
    "                        # Extract id from https://openalex.org/A5100341522\n",
    "                        if authorId:\n",
    "                            authorId = authorId[21:]\n",
    "                            url = f\"https://api.openalex.org/authors/{authorId}\"\n",
    "                            response = requests.get(url)\n",
    "                            if response.status_code == 200:\n",
    "                                authorData = response.json()\n",
    "                                authorScopusId = authorData.get(\"ids\", {}).get(\"scopus\", None)\n",
    "                                authorOrchidId = authorData.get(\"ids\", {}).get(\"orcid\", None)\n",
    "                                \n",
    "                                    \n",
    "                                if authorScopusId != None or authorOrchidId != None:\n",
    "                                    # Extract id from http://www.scopus.com/inward/authorDetails.url?authorID=36455008000&partnerID=MN8TOARS\n",
    "                                    if authorScopusId != None:\n",
    "                                        url = authorScopusId\n",
    "                                        parsed_url = urlparse(url)\n",
    "                                        # Extract the query parameters\n",
    "                                        query_params = parse_qs(parsed_url.query)\n",
    "                                        \n",
    "                                        \n",
    "                                        # Get the authorID\n",
    "                                        authorIDReal = query_params.get(\"authorID\", [None])[0]\n",
    "                                        \n",
    "                                        authorIDReal = re.findall(r'\\d+', url)\n",
    "                                        authorIDReal = authorIDReal[0]                                    \n",
    "                                        scopusURL = \"https://api.elsevier.com/content/search/scopus?query=AU-ID(\" + authorIDReal + \")&view=COMPLETE\"\n",
    "                                    \n",
    "                                        headers = {\n",
    "                                            \"X-ELS-APIKey\": getElsevierAPIKey(),\n",
    "                                            \"Accept\": \"application/json\"\n",
    "                                        }\n",
    "                                        \n",
    "                                        response = requests.get(scopusURL, headers=headers)\n",
    "                                        \n",
    "                                        if response.status_code == 200:\n",
    "                                            response = response.json()\n",
    "                                            \n",
    "                                            authorPublicationHistory = []\n",
    "                                            log = response.get(\"search-results\", {}).get(\"entry\", None)\n",
    "                                            if log == None:\n",
    "                                                authorPublicationHistory = None\n",
    "                                                out += 1\n",
    "                                                break\n",
    "                                            \n",
    "                                            for paper in log:\n",
    "                                                pTitle = paper.get(\"dc:title\", None)\n",
    "                                                pAbstract = paper.get(\"dc:description\", None)\n",
    "                                                pDOI = paper.get(\"prism:doi\", None)\n",
    "                                                pCitationCount = paper.get(\"citedby-count\", None)\n",
    "                                                pScopusID = paper.get(\"dc:identifier\", None)\n",
    "                                                pAuthors = paper.get(\"author\", None)\n",
    "                                                pA = []\n",
    "                                                if pAuthors:\n",
    "                                                    for author in pAuthors:\n",
    "                                                        f = author.get(\"given-name\", None)\n",
    "                                                        l = author.get(\"surname\", None)\n",
    "                                                        if f != None and l != None:\n",
    "                                                            a = f + \" \" + l\n",
    "                                                            pA.append(a)\n",
    "                                                authorPublicationHistory.append({\"title\": pTitle, \"abstract\": pAbstract, \"doi\": pDOI, \"citationCount\":pCitationCount, \"scopusID\": pScopusID, \"authors\": pA})\n",
    "                                            \n",
    "                                        else:\n",
    "                                            print(\"Error fetching data for DOI: \", doi)\n",
    "                                            break\n",
    "                                    else:\n",
    "                                        # url = https://orcid.org/0000-0002-7864-2578'\n",
    "                                        authorIDReal = authorOrchidId[18:]\n",
    "                                        scopusURL = \"https://api.elsevier.com/content/search/scopus?query=orcid(\" + authorIDReal + \")&view=COMPLETE\"\n",
    "                                    \n",
    "                                        headers = {\n",
    "                                            \"X-ELS-APIKey\": getElsevierAPIKey(),\n",
    "                                            \"Accept\": \"application/json\"\n",
    "                                        }\n",
    "                                        \n",
    "                                        response = requests.get(scopusURL, headers=headers)\n",
    "                                        \n",
    "                                        if response.status_code == 200:\n",
    "                                            response = response.json()\n",
    "                                            \n",
    "                                            authorPublicationHistory = []\n",
    "                                            log = response.get(\"search-results\", {}).get(\"entry\", None)\n",
    "                                            if log == None:\n",
    "                                                authorPublicationHistory = None\n",
    "                                                out += 1\n",
    "                                                break\n",
    "                                            \n",
    "                                            for paper in log:\n",
    "                                                pTitle = paper.get(\"dc:title\", None)\n",
    "                                                pAbstract = paper.get(\"dc:description\", None)\n",
    "                                                pDOI = paper.get(\"prism:doi\", None)\n",
    "                                                pCitationCount = paper.get(\"citedby-count\", None)\n",
    "                                                pScopusID = paper.get(\"dc:identifier\", None)\n",
    "                                                pAuthors = paper.get(\"author\", None)\n",
    "                                                pA = []\n",
    "                                                if pAuthors:\n",
    "                                                    for author in pAuthors:\n",
    "                                                        f = author.get(\"given-name\", None)\n",
    "                                                        l = author.get(\"surname\", None)\n",
    "                                                        if f != None and l != None:\n",
    "                                                            \n",
    "                                                            a = f + \" \" + l\n",
    "                                                            pA.append(a)\n",
    "                                                authorPublicationHistory.append({\"title\": pTitle, \"abstract\": pAbstract, \"doi\": pDOI, \"citationCount\":pCitationCount, \"scopusID\": pScopusID, \"authors\": pA})\n",
    "                                        else:\n",
    "                                            print(\"Error fetching data for DOI: \", doi)\n",
    "                                            break\n",
    "                                    \n",
    "                                    \n",
    "                                else:\n",
    "                                    #print(\"No Scopus ID\")\n",
    "                                    #print(authorOrchidId)\n",
    "                                    #print(authorData.get(\"ids\", {}))\n",
    "                                    authorScopusId = None\n",
    "                                    break\n",
    "                        else:\n",
    "                            notFound = False\n",
    "                            break\n",
    "                        if notFound:\n",
    "                            new_row = {\n",
    "                                \"SubmissionID\": submissionID,\n",
    "                                \"SubmissionYear\": submissionYear,\n",
    "                                \"SubmissionTitle\": submissionTitle,\n",
    "                                \"SubmissionAbstract\": None,\n",
    "                                \"firstName\": firstName,\n",
    "                                \"middleName\": middleName,\n",
    "                                \"lastName\": lastName,\n",
    "                                \"isFirstAuthor\": isFirstAuthor,\n",
    "                                \"city\": None,\n",
    "                                \"country\": country,\n",
    "                                \"countryCode\": countryCode,\n",
    "                                \"institution\": institution,\n",
    "                                \"doi\": doi,\n",
    "                                \"authorID\": authorIDReal,\n",
    "                                \"authorPublicationHistory\": authorPublicationHistory,\n",
    "                                \"match\": match\n",
    "                            }\n",
    "                            inside_data.append(new_row)\n",
    "                    if break_outer_loop == False:\n",
    "                        for row in inside_data:\n",
    "                            openalex_data.append(row)\n",
    "                    else:\n",
    "                        print(\"Current Size:\", len(openalex_data))\n",
    "                        missedOut += 1\n",
    "                        print(\"Missed Ones: \", missedOut)\n",
    "                    \n",
    "    openalex_df = pd.DataFrame(openalex_data)\n",
    "\n",
    "    openalex_df.to_csv(\"./data/openalex_data.csv\", index=False)\n",
    "\n",
    "print(\"Total Missed Ones: \", missedOut)\n",
    "print(\"Total Inside Ones: \", inside)\n",
    "\n",
    "# Print information about the data\n",
    "print(openalex_df.info())\n",
    "print(openalex_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 4479.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50 entries, 0 to 49\n",
      "Data columns (total 22 columns):\n",
      " #   Column                              Non-Null Count  Dtype  \n",
      "---  ------                              --------------  -----  \n",
      " 0   SubmissionID                        50 non-null     object \n",
      " 1   SubmissionYear                      50 non-null     int64  \n",
      " 2   SubmissionTitle                     50 non-null     object \n",
      " 3   SubmissionAbstract                  50 non-null     object \n",
      " 4   firstName                           50 non-null     object \n",
      " 5   middleName                          13 non-null     object \n",
      " 6   lastName                            50 non-null     object \n",
      " 7   isFirstAuthor                       50 non-null     int64  \n",
      " 8   city                                0 non-null      float64\n",
      " 9   country                             50 non-null     object \n",
      " 10  countryCode                         50 non-null     object \n",
      " 11  institution                         50 non-null     object \n",
      " 12  doi                                 50 non-null     object \n",
      " 13  authorID                            50 non-null     object \n",
      " 14  authorPublicationHistory            50 non-null     object \n",
      " 15  match                               50 non-null     int64  \n",
      " 16  fullName                            50 non-null     object \n",
      " 17  title_embedding                     50 non-null     object \n",
      " 18  abstract_embedding                  50 non-null     object \n",
      " 19  doi_embedding                       50 non-null     object \n",
      " 20  authorPublicationHistory_embedding  50 non-null     object \n",
      " 21  cluster_filter                      50 non-null     object \n",
      "dtypes: float64(1), int64(3), object(18)\n",
      "memory usage: 8.7+ KB\n",
      "None\n",
      "                 SubmissionID  SubmissionYear  \\\n",
      "0             /10.1101/188524            2017   \n",
      "1             /10.1101/188524            2017   \n",
      "2             /10.1101/783175            2019   \n",
      "3  /10.1101/2020.06.30.176537            2020   \n",
      "4  /10.1101/2020.06.30.176537            2020   \n",
      "\n",
      "                                     SubmissionTitle  \\\n",
      "0  characterizing highly dynamic conformational s...   \n",
      "1  characterizing highly dynamic conformational s...   \n",
      "2  dynamic reconfiguration fragmentation and inte...   \n",
      "3  attenuated subcomponent vaccine design targeti...   \n",
      "4  attenuated subcomponent vaccine design targeti...   \n",
      "\n",
      "                                  SubmissionAbstract firstName middleName  \\\n",
      "0  biomacromolecules carry out complicated functi...     eitan        NaN   \n",
      "1  biomacromolecules carry out complicated functi...  antonino        NaN   \n",
      "2  general anesthetics are routinely used to indu...    corson         N.   \n",
      "3  the novel coronavirus disease covid19 caused b...    onyeka         S.   \n",
      "4  the novel coronavirus disease covid19 caused b...   rebecca   Chinyelu   \n",
      "\n",
      "       lastName  isFirstAuthor  city        country  ...  \\\n",
      "0        lerner              1   NaN  United States  ...   \n",
      "1    ingargiola              0   NaN  United States  ...   \n",
      "2   areshenkoff              0   NaN         Canada  ...   \n",
      "3   chukwudozie              1   NaN        Nigeria  ...   \n",
      "4  chukwuanukwu              0   NaN        Nigeria  ...   \n",
      "\n",
      "                      doi             authorID  \\\n",
      "0       10.1063/1.5004606          35205792300   \n",
      "1       10.1063/1.5004606          23973120100   \n",
      "2  10.1093/cercor/bhaa085  0000-0001-9072-9185   \n",
      "3    10.1155/2020/2837670  0000-0002-0814-6798   \n",
      "4    10.1155/2020/2837670  0000-0001-5023-9560   \n",
      "\n",
      "                            authorPublicationHistory match  \\\n",
      "0  [{'title': 'rapid and specific detection of na...     1   \n",
      "1  [{'title': 'erratum monte carlo diffusionenhan...     1   \n",
      "2  [{'title': 'distinct patterns of connectivity ...     1   \n",
      "3  [{'title': 'the relevance of bioinformatics ap...     1   \n",
      "4  [{'title': 'the role of immuneinflammatory mar...     1   \n",
      "\n",
      "                        fullName  \\\n",
      "0                   eitan lerner   \n",
      "1            antonino ingargiola   \n",
      "2          corson n. areshenkoff   \n",
      "3          onyeka s. chukwudozie   \n",
      "4  rebecca chinyelu chukwuanukwu   \n",
      "\n",
      "                                     title_embedding  \\\n",
      "0  [0.000631210277788341, -0.06552567332983017, -...   \n",
      "1  [0.000631210277788341, -0.06552567332983017, -...   \n",
      "2  [-0.03589945659041405, 0.03250805288553238, -0...   \n",
      "3  [0.018001500517129898, -0.033130768686532974, ...   \n",
      "4  [0.018001500517129898, -0.033130768686532974, ...   \n",
      "\n",
      "                                  abstract_embedding  \\\n",
      "0  [0.007256368640810251, -0.03036230057477951, -...   \n",
      "1  [0.007256368640810251, -0.03036230057477951, -...   \n",
      "2  [-0.018003256991505623, 0.04315100610256195, -...   \n",
      "3  [-0.00747875077649951, -0.04243578389286995, 0...   \n",
      "4  [-0.00747875077649951, -0.04243578389286995, 0...   \n",
      "\n",
      "                                       doi_embedding  \\\n",
      "0  [0.007630346342921257, -0.03242341801524162, -...   \n",
      "1  [0.007630346342921257, -0.03242341801524162, -...   \n",
      "2  [-0.0036318886559456587, -0.04171673208475113,...   \n",
      "3  [-0.014353901147842407, -0.019061246886849403,...   \n",
      "4  [-0.014353901147842407, -0.019061246886849403,...   \n",
      "\n",
      "                  authorPublicationHistory_embedding  \\\n",
      "0  [{'title_embedding': [0.00456725899130106, -0....   \n",
      "1  [{'title_embedding': [-0.011444708332419395, -...   \n",
      "2  [{'title_embedding': [-0.05066244304180145, 0....   \n",
      "3  [{'title_embedding': [-0.027665186673402786, 0...   \n",
      "4  [{'title_embedding': [0.02183222956955433, -0....   \n",
      "\n",
      "                                      cluster_filter  \n",
      "0  [{'title': 'rapid and specific detection of na...  \n",
      "1  [{'title': 'erratum monte carlo diffusionenhan...  \n",
      "2  [{'title': 'distinct patterns of connectivity ...  \n",
      "3  [{'title': 'attenuated subcomponent vaccine de...  \n",
      "4  [{'title': 'neutrophil extracellular traps cha...  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "def clean_abstract(abstract):\n",
    "    # Remove <jats:title> and </jats:title> tags and any content between them\n",
    "    abstract = re.sub(r'<jats:title>[^>]+</jats:title>', '', abstract)\n",
    "    # Remove <jats:p> and </jats:p> tags\n",
    "    abstract = re.sub(r'<jats:p>|</jats:p>', '', abstract)\n",
    "    # Remove any other <jats:*> tags\n",
    "    abstract = re.sub(r'<jats:[^>]+>', '', abstract)\n",
    "    # Remove </jats:sec> tags\n",
    "    abstract = re.sub(r'</jats:sec>', '', abstract)\n",
    "    # Remove all other HTML tags\n",
    "    abstract = re.sub(r'<[^>]+>', '', abstract)\n",
    "    return abstract\n",
    "\n",
    "def fetch_crossref_data(doi):\n",
    "    url = f\"https://api.crossref.org/works/{doi}\"\n",
    "    #print(url)\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        return data\n",
    "    else:\n",
    "        print(f\"Error fetching data for DOI: {doi}\")\n",
    "        return None\n",
    "    \n",
    "\n",
    "def extend_dataset_with_crossref(submissionIds):\n",
    "    listOfIdAbstract = {}\n",
    "    \n",
    "    print(submissionIds[:10])\n",
    "    print(len(submissionIds))\n",
    "    i = 0\n",
    "    \n",
    "    for id in tqdm.tqdm(submissionIds):\n",
    "        data = fetch_crossref_data(id)\n",
    "        if data:\n",
    "            abstract = data.get(\"message\", {}).get(\"abstract\", None)\n",
    "            if abstract:\n",
    "                abstract = clean_abstract(abstract)\n",
    "                listOfIdAbstract[id] = abstract\n",
    "            else:\n",
    "                listOfIdAbstract[id] = None\n",
    "                \n",
    "    return listOfIdAbstract\n",
    "\n",
    "openalex_df[\"SubmissionAbstract\"] = openalex_df[\"SubmissionAbstract\"].astype(object)\n",
    "print(len(openalex_df))\n",
    "    \n",
    "if not os.path.exists(\"./data/mini_dataset_v3.csv\"):\n",
    "    # Get all the submissionId from the extended dataset\n",
    "    submissionIds = openalex_df[\"SubmissionID\"].tolist()\n",
    "    # Remove duplicates\n",
    "    print(len(submissionIds))\n",
    "    submissionIds = list(set(submissionIds))\n",
    "    print(len(submissionIds))\n",
    "    \n",
    "    print(len(openalex_df))\n",
    "    listOfIdAbstract = extend_dataset_with_crossref(submissionIds)\n",
    "    for id, abstract in tqdm.tqdm(listOfIdAbstract.items()):\n",
    "        if abstract is not None:\n",
    "            openalex_df.loc[openalex_df[\"SubmissionID\"] == id, \"SubmissionAbstract\"] = abstract\n",
    "        else:\n",
    "            openalex_df.drop(openalex_df[openalex_df[\"SubmissionID\"] == id].index, inplace=True)\n",
    "    \n",
    "    openalex_df.to_csv(\"./data/mini_dataset_v3.csv\", index=False)\n",
    "else:\n",
    "    openalex_df = pd.read_csv(\"./data/mini_dataset_v3.csv\")\n",
    "\n",
    "# Clean all the titles in the dataset\n",
    "for index, row in tqdm.tqdm(openalex_df.iterrows(), total=openalex_df.shape[0]):\n",
    "    title = row[\"SubmissionTitle\"]\n",
    "    cleanedTitle = clean_abstract(title)\n",
    "    openalex_df.loc[index, \"SubmissionTitle\"] = cleanedTitle\n",
    "\n",
    "openalex_df.to_csv(\"./data/mini_dataset_v3.csv\", index=False)\n",
    "\n",
    "print(openalex_df.info())\n",
    "print(openalex_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-project-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
